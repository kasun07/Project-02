{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join the data from Part 1 with the data from Part 2 to create a new dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"fsq3XRUAarAkYkZaUxo7U14qSYIS91CYwbt1bF94/FymeqU=\"\n",
    "}\n",
    "\n",
    "url = \"https://api.foursquare.com/v3/places/search\"\n",
    "params = {\n",
    "    'radius': 1000,\n",
    "    'll': '40.7243,-74.0018',\n",
    "    'query': 'coffee',\n",
    "}\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    print(response.text)\n",
    "\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "data = response.json()\n",
    "    \n",
    "places = data.get('results', [])\n",
    "df1 = pd.DataFrame(places)\n",
    "\n",
    "# print(df1)\n",
    "\n",
    "url = \"https://api.yelp.com/v3/businesses/search\"\n",
    "params = {\n",
    "    'radius' : 1000,\n",
    "    'latitude': 40.7243,\n",
    "    'longitude' : -74.0018,\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"Authorization\": \"Bearer oCE9nQh4V-FyXHEU0GDnZV-cdmqUWjYgoS_7OkG7XEEi8KDgtqVRZlYkcQn_q94PrjNaIhgq7nfLWb0wNk2wn_2RNBjm_lm4vGIkkWW6OhQ9xru_q3QRjywgg6myZnYx\"\n",
    "}\n",
    "\n",
    "response_yelp = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "if response_yelp.status_code == 200:\n",
    "    print(response_yelp.text)\n",
    "\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "\n",
    "data_yelp = response_yelp.json()\n",
    "    \n",
    "yelp_places = data_yelp.get('businesses', [])\n",
    "df2 = pd.DataFrame(yelp_places)\n",
    "\n",
    "# print(df2)\n",
    "\n",
    "combined_df = pd.concat([df1, df2], axis=0, ignore_index=True)\n",
    "\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide a visualization that you used as part of your EDA process. Explain the initial pattern or relationship you discoved through this visualization. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Retrieve bike station data (DF1)\n",
    "url = \"http://api.citybik.es/v2/networks\"\n",
    "response = requests.get(url)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response_data = response.json()\n",
    "    networks = response_data.get('networks', [])\n",
    "    vancouver_network = None\n",
    "    \n",
    "    for i in networks:\n",
    "        if i['location']['city'].lower() == 'vancouver':\n",
    "            vancouver_network = i\n",
    "            break\n",
    "    \n",
    "    if vancouver_network:\n",
    "        network_id = vancouver_network['id']\n",
    "        details_url = f\"http://api.citybik.es/v2/networks/{network_id}\"\n",
    "        details_response = requests.get(details_url)\n",
    "        \n",
    "        if details_response.status_code == 200:\n",
    "            vancouver_details = details_response.json()\n",
    "            stations = vancouver_details['network']['stations']\n",
    "            \n",
    "            data = [{'Name': station['name'], 'Latitude': station['latitude'], 'Longitude': station['longitude']} for station in stations]\n",
    "            df1 = pd.DataFrame(data)\n",
    "        else:\n",
    "            raise Exception(f\"Failed to retrieve details for Vancouver network: {details_response.status_code}\")\n",
    "    else:\n",
    "        raise Exception(\"Vancouver network not found.\")\n",
    "else:\n",
    "    raise Exception(f\"Failed to retrieve data: {response.status_code}\")\n",
    "\n",
    "headers = {\n",
    "    \"Accept\": \"application/json\",\n",
    "    \"Authorization\": \"fsq3XRUAarAkYkZaUxo7U14qSYIS91CYwbt1bF94/FymeqU=\"\n",
    "}\n",
    "\n",
    "url = \"https://api.foursquare.com/v3/places/search\"\n",
    "params = {\n",
    "    'radius': 100000,\n",
    "    'll': '49.262487,-123.114397',\n",
    "    'categories': '13065,13056', \n",
    "    'fields': 'name,geocodes'\n",
    "}\n",
    "\n",
    "response = requests.get(url, headers=headers, params=params)\n",
    "\n",
    "if response.status_code == 200:\n",
    "    response_data = response.json()\n",
    "    places = response_data.get('results', [])\n",
    "    \n",
    "    dining_and_drinking = [\n",
    "        {\n",
    "            'Name': place.get('name'),\n",
    "            'Latitude': place['geocodes']['main']['latitude'] if 'geocodes' in place and 'main' in place['geocodes'] else None,\n",
    "            'Longitude': place['geocodes']['main']['longitude'] if 'geocodes' in place and 'main' in place['geocodes'] else None\n",
    "        }\n",
    "        for place in places\n",
    "    ]\n",
    "    \n",
    "    df2 = pd.DataFrame(dining_and_drinking)\n",
    "else:\n",
    "    raise Exception(f\"Error: {response.status_code}, {response.text}\")\n",
    "\n",
    "df1['Type'] = 'Bike Station'\n",
    "df2['Type'] = 'Restaurant/Bar'\n",
    "combined_df = pd.concat([df1, df2])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(df1['Longitude'], df1['Latitude'], label='Bike Stations', color='blue', alpha=0.6, edgecolors='w', s=100)\n",
    "plt.scatter(df2['Longitude'], df2['Latitude'], label='Restaurants/Bars', color='red', alpha=0.6, edgecolors='w', s=100)\n",
    "plt.xlabel('Longitude')\n",
    "plt.ylabel('Latitude')\n",
    "plt.title('Bike Stations and Restaurants/Bars in Vancouver')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put all your results in an SQLite3 database (remember, SQLite stores its databases as files in your local machine - make sure to create your database in your project's data/ directory!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def convert_complex_types_to_json(df):\n",
    "    for column in df.columns:\n",
    "        if df[column].apply(lambda x: isinstance(x, (list, dict))).any():\n",
    "            df[column] = df[column].apply(json.dumps)\n",
    "    return df\n",
    "\n",
    "conn = sqlite3.connect('data/places_data.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "combined_df = convert_complex_types_to_json(combined_df)\n",
    "\n",
    "combined_df.to_sql('places', conn, if_exists='replace', index=False)\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "conn = sqlite3.connect('data/places_data.db')\n",
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT * FROM places LIMIT 5\")\n",
    "rows = cursor.fetchall()\n",
    "for row in rows:\n",
    "    print(row)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data before and after the join to validate your data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
